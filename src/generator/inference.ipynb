{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'GoToCompany/gemma2-9b-cpt-sahabatai-v1-instruct'\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "train_set = 'id_jvsu_claude'\n",
    "test_language = 'su'\n",
    "model_path = f\"outputs/{model_name.split('/')[-1]}/{train_set}\"\n",
    "import os\n",
    "import re\n",
    "checkpoint = 'checkpoint-1000'\n",
    "# checkpoint = max(os.listdir(model_path), key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = f\"{model_path}/{checkpoint}\",\n",
    "    max_seq_length = 8192,\n",
    "    load_in_4bit = True,\n",
    "    # token = \"hf_...\"\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_path = f\"../../dataset/test/test_{test_language}.csv\"\n",
    "def load_test_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    contexts = []\n",
    "    endings = []\n",
    "    EOS_TOKEN = tokenizer.eos_token\n",
    "    for idx, row in data.iterrows():\n",
    "        sents = []\n",
    "        for i in [4,3,2,1]:\n",
    "            current_sentence = row[f'sentence_{i}']\n",
    "            current_sentence = current_sentence + '.' if current_sentence[-1] != '.' else current_sentence\n",
    "            sents.insert(0, current_sentence)\n",
    "        context = ' '.join(sents) \n",
    "        ending = row['correct_ending']\n",
    "        # ending2 = row['incorrect_ending']\n",
    "        contexts.append(context)\n",
    "        endings.append(ending)\n",
    "\n",
    "    # convert to huggingface dataset\n",
    "    from datasets import Dataset\n",
    "    dataset = Dataset.from_dict({'context': contexts, 'ending': endings})\n",
    "    def formatting_prompts_func(examples):\n",
    "        contexts  = examples[\"context\"]\n",
    "        endings = examples[\"ending\"]\n",
    "        texts = []\n",
    "        for context, ending in zip(contexts, endings):\n",
    "            chat = [\n",
    "                {\"role\": \"user\", \"content\": f\"Generate the ending for the following given story context\\nStory Context: {context}\"},\n",
    "            ]\n",
    "            text = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "            texts.append(text)\n",
    "        return { \"text\" : texts, }\n",
    "    dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
    "    return dataset\n",
    "dataset = load_test_data(data_path)\n",
    "contexts = dataset['text']\n",
    "correct_endings = dataset['ending']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "context = contexts[-25]\n",
    "inputs = tokenizer(context,return_tensors = \"pt\").to(\"cuda\")\n",
    "res = model.generate(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask, max_new_tokens=128, use_cache=True, do_sample=False)\n",
    "predicted_ending = tokenizer.decode(res[0][len(inputs.input_ids[0]):], skip_special_tokens=True)\n",
    "predicted_ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
