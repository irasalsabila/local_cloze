{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-4o\") # temperature 0.7 (default)\n",
    "\n",
    "# from langchain_cohere import ChatCohere\n",
    "\n",
    "# os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter your Cohere API Key: \")\n",
    "\n",
    "# model = ChatCohere(model=\"command-r-plus-08-2024\", temperature=0.7)\n",
    "\n",
    "# from langchain_groq import ChatGroq\n",
    "\n",
    "# model = ChatGroq(\n",
    "#     model=\"mixtral-8x7b-32768\",\n",
    "#     temperature=0.7,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     groq_api_key=\"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\",\n",
    "#     # max_retries=2,\n",
    "#     # other params...\n",
    "# )\n",
    "\n",
    "from langchain_together import ChatTogether\n",
    "\n",
    "model = ChatTogether(\n",
    "    model=\"google/gemma-2-27b-it\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    api_key=\"5acc40de073869c904bc7929c58cd6b984435dfc6ff4655756f43eb256bb64db\"\n",
    "    # max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from prompt import sundanese_overgeneration_prompt_gemma, topics\n",
    "from tenacity import retry\n",
    "\n",
    "chain = sundanese_overgeneration_prompt_gemma | model | StrOutputParser()\n",
    "\n",
    "@retry\n",
    "def generate_25_examples(topic):\n",
    "    return chain.batch([{\"topic\":topic}] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "# from langchain_core.tracers.context import tracing_v2_enabled\n",
    "import os\n",
    "\n",
    "# os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "# os.environ['LANGCHAIN_API_KEY'] = \"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\"\n",
    "\n",
    "\n",
    "# responses = []\n",
    "# topic_pointer = 0\n",
    "# i=0\n",
    "\n",
    "# with tracing_v2_enabled(project_name=\"gemma2-27B-sundanese-overgeneration\"):\n",
    "while len(responses) < 400:\n",
    "    print(i)\n",
    "    res = generate_25_examples(topics[topic_pointer])\n",
    "    responses.extend(res)\n",
    "    topic_pointer = (topic_pointer+1)%len(topics)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_generated_stories(res):\n",
    "    # Split the input based on double new lines to separate each story\n",
    "    res = re.sub(r'\\d+\\.\\s*', '', res)\n",
    "    res = res.split('\\n')\n",
    "    stories = []\n",
    "    premise, correct_ending, incorrect_ending = None, None, None\n",
    "    for line in res:\n",
    "        if 'story premise' in line.lower():\n",
    "            premise = line.split(':')[-1].strip()\n",
    "        elif 'incorrect ending' in line.lower():\n",
    "            incorrect_ending = line.split(\":\")[-1].strip()\n",
    "            stories.append({\"premise\": premise, \"correct_ending\": correct_ending, \"incorrect_ending\": incorrect_ending})\n",
    "            premise, correct_ending, incorrect_ending = None, None, None\n",
    "        elif 'correct ending' in line.lower():\n",
    "            correct_ending = line.split(':')[-1].strip()\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_formatted = [parse_generated_stories(res) for res in responses]\n",
    "responses_final = [res for subset in responses_formatted for res in subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd \n",
    "\n",
    "pkl.dump(responses_final, open(\"generated_stories.pkl\", 'wb'))\n",
    "pd.DataFrame(responses_final).to_csv(\"train_gemma2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1248"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responses_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_cloze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
