{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-4o\") # temperature 0.7 (default)\n",
    "\n",
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter your Cohere API Key: \")\n",
    "\n",
    "model = ChatCohere(model=\"command-r-plus-08-2024\", temperature=0.7)\n",
    "\n",
    "# from langchain_groq import ChatGroq\n",
    "\n",
    "# model = ChatGroq(\n",
    "#     model=\"llama-3.1-70b-versatile\",\n",
    "#     temperature=0.7,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     groq_api_key=\"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\",\n",
    "#     # max_retries=2,\n",
    "#     # other params...\n",
    "# )\n",
    "\n",
    "# from langchain_together import ChatTogether\n",
    "\n",
    "# model = ChatTogether(\n",
    "#     model=\"google/gemma-2-27b-it\",\n",
    "#     temperature=0.7,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     api_key=\"5acc40de073869c904bc7929c58cd6b984435dfc6ff4655756f43eb256bb64db\"\n",
    "#     # max_retries=2,\n",
    "#     # other params...\n",
    "# )\n",
    "\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# model = ChatAnthropic(\n",
    "#     model=\"claude-3-opus-20240229\",\n",
    "#     temperature=0.7,\n",
    "#     timeout=None,\n",
    "#     api_key=\"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\"\n",
    "#     # max_retries=2,\n",
    "#     # other params...\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from prompt import sundanese_overgeneration_prompt, topics\n",
    "from tenacity import retry\n",
    "\n",
    "chain = sundanese_overgeneration_prompt | model | StrOutputParser()\n",
    "\n",
    "@retry\n",
    "def generate_25_examples(topic):\n",
    "    return chain.batch([{\"topic\":topic}] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "topic_pointer = 0\n",
    "i=0\n",
    "\n",
    "while len(responses) < 50:\n",
    "    print(i)\n",
    "    current_topic = topics[topic_pointer]\n",
    "    res = generate_25_examples(current_topic)\n",
    "    res = [(current_topic, r) for r in res]\n",
    "    responses.extend(res)\n",
    "    topic_pointer = (topic_pointer+1)%len(topics)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_generated_stories(res, topic):\n",
    "    # Split the input based on double new lines to separate each story\n",
    "    res = re.sub(r'\\d+\\.\\s*', '', res)\n",
    "    res = res.split('\\n')\n",
    "    stories = []\n",
    "    premise, correct_ending, incorrect_ending = None, None, None\n",
    "    for line in res:\n",
    "        if 'story premise' in line.lower():\n",
    "            premise = line.split(':')[-1].strip()\n",
    "        elif 'incorrect ending' in line.lower():\n",
    "            incorrect_ending = line.split(\":\")[-1].strip()\n",
    "            stories.append({\"topic\": topic, \"premise\": premise, \"correct_ending\": correct_ending, \"incorrect_ending\": incorrect_ending})\n",
    "            premise, correct_ending, incorrect_ending = None, None, None\n",
    "        elif 'correct ending' in line.lower():\n",
    "            correct_ending = line.split(':')[-1].strip()\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_formatted = [parse_generated_stories(res, topic) for topic, res in responses]\n",
    "responses_final = [res for subset in responses_formatted for res in subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd \n",
    "\n",
    "pkl.dump(responses_final, open(\"generated_stories.pkl\", 'wb'))\n",
    "pd.DataFrame(responses_final).to_csv(\"train_rplus.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_cloze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
